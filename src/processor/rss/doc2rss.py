"""
    Created by howie.hu at 2021-12-27.
    Description: RSSç›¸å…³è„šæœ¬
        - ç”ŸæˆRSSå‘½ä»¤: PIPENV_DOTENV_LOCATION=./pro.env pipenv run python src/processor/rss/doc2rss.py
    Changelog: all notable changes to this file will be documented
"""
import time

from datetime import datetime

import pytz

from feedgen.feed import FeedGenerator

from src.common.db_utils import get_doc_source_name_dict
from src.config import Config
from src.databases.mongodb_base import MongodbManager
from src.databases.mongodb_tools import mongodb_find, mongodb_update_data
from src.processor.rss.utils import get_rss_doc_link
from src.utils import LOGGER


def to_rss(doc_source_list: list = None, link_source: str = "self"):
    """ä¸ºæ–‡ç« ç”ŸæˆRSS

    Args:
        doc_source_list (list, optional): æ–‡ç« æ¥æºåˆ—è¡¨. Defaults to None.
        link_source (str, optional): é“¾æ¥è¿”å›è§„åˆ™ç±»å‹ï¼ŒåŸºäºå¤‡ä»½å™¨ï¼Œç›®å‰æ”¯æŒå­—æ®µå¦‚ä¸‹:
            - self: ä¸æ›¿æ¢ï¼Œç”¨æœ¬èº«çš„ doc_link
            - mongodb: ç”¨ liuli api æœåŠ¡çš„è¿æ¥ {LL_DOMAIN}/backup/{doc_source}/{doc_source_name}/{doc_name}
            - github: ç”¨ github ä»“åº“åœ°å€ {LL_GITHUB_DOMAIN}/{doc_source}/{doc_source_name}/{doc_name}.html
    """
    # è·å– doc_source ä¸‹çš„ doc_source_name ç»„æˆçš„å­—å…¸
    doc_source_name_dict: dict = get_doc_source_name_dict(doc_source_list)
    # æ•°æ®åº“åˆå§‹åŒ–
    mongo_base = MongodbManager.get_mongo_base(mongodb_config=Config.MONGODB_CONFIG)
    coll_articles_conn = mongo_base.get_collection(
        coll_name="liuli_articles", db_name="liuli"
    )
    coll_rss_conn = mongo_base.get_collection(coll_name="liuli_rss", db_name="liuli")
    for doc_source, doc_source_name_list in doc_source_name_dict.items():
        for doc_source_name in doc_source_name_list:
            filter_dict = {"doc_source_name": doc_source_name, "doc_source": doc_source}
            return_dict = {
                "doc_source_name": 1,
                "doc_source": 1,
                "doc_name": 1,
                "doc_des": 1,
                "doc_link": 1,
                "doc_core_html": 1,
                "doc_author": 1,
                "doc_date": 1,
                "doc_ts": 1,
            }
            # æå–æ–‡ç« 
            f_db_res = mongodb_find(
                coll_conn=coll_articles_conn,
                filter_dict=filter_dict,
                return_dict=return_dict,
                sorted_key="doc_ts",
                # å€’åº
                sorted_index=1,
                # æœ€è¿‘10ç¯‡æ–‡ç« 
                limit=10,
            )
            f_db_satus, f_db_info = f_db_res["status"], f_db_res["info"]
            if f_db_satus:
                if f_db_info:
                    # æŸ¥è¯¢æˆåŠŸä¸”æœ‰æ•°æ®
                    fg = FeedGenerator()
                    fg.id(doc_source_name)
                    fg.title(doc_source_name)
                    fg.author({"name": "liuli"})
                    for each in f_db_info:
                        doc_name = each["doc_name"]
                        if not doc_name:
                            continue
                        doc_des = each["doc_des"]
                        doc_link = get_rss_doc_link(
                            link_source=link_source, doc_data=each
                        )
                        doc_author = each["doc_author"] or "liuli_defaults"
                        doc_ts = each["doc_ts"]
                        # doc_core_html = each.get("doc_core_html", "")
                        # æ„é€  RSS
                        fe = fg.add_entry()
                        article_id = f"{doc_source} - {doc_source_name} - {doc_name}"
                        fe.id(article_id)
                        fe.title(doc_name)
                        fe.link(href=doc_link)
                        fe.description(doc_des)
                        fe.author(name=f"{article_id} - {doc_author}")
                        # å†…å®¹å…ˆä¸ºç©º
                        fe.content("")
                        fe.pubDate(
                            pytz.timezone("Asia/Shanghai").localize(
                                datetime.fromtimestamp(doc_ts)
                            )
                        )
                    try:
                        rss_data = str(fg.atom_str(pretty=True), "utf-8")
                        # æ›´æ–° RSS å†…å®¹
                        rss_db_data = {
                            "doc_source": doc_source,
                            "doc_source_name": doc_source_name,
                            "rss_data": rss_data,
                            "updated_at": int(time.time()),
                        }
                        rss_db_res = mongodb_update_data(
                            coll_conn=coll_rss_conn,
                            filter_dict=filter_dict,
                            update_data={"$set": rss_db_data},
                        )
                        if rss_db_res["status"]:
                            msg = f"ğŸ˜€ ä¸º{doc_source}: {doc_source_name} çš„ {len(f_db_info)} ç¯‡æ–‡ç« ç”ŸæˆRSSæˆåŠŸ!"
                        else:
                            msg = f"ğŸ˜¿ ä¸º{doc_source}: {doc_source_name} çš„ {len(f_db_info)} ç¯‡æ–‡ç« ç”ŸæˆRSSå¤±è´¥!"
                    except Exception as e:
                        msg = f"ğŸ˜¿ ä¸º{doc_source}: {doc_source_name} çš„ {len(f_db_info)} ç¯‡æ–‡ç« ç”ŸæˆRSSå¤±è´¥, éæ³•æ•°æ®! {e}"

                else:
                    msg = f"æŸ¥è¯¢æˆåŠŸ {doc_source}: {doc_source_name} æš‚æ— å†å²æ–‡ç« !"
                LOGGER.info(msg)
            else:
                # æŸ¥è¯¢å¤±è´¥
                LOGGER.error(f"{doc_source}: {doc_source_name} å†å²æ–‡ç« æŸ¥è¯¢å¤±è´¥!")


if __name__ == "__main__":
    to_rss()
