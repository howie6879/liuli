"""
    Created by howie.hu at 2021-12-27.
    Description: RSSç›¸å…³è„šæœ¬
        - ç”ŸæˆRSSå‘½ä»¤: PIPENV_DOTENV_LOCATION=./online.env pipenv run python src/processor/rss_utils.py
    Changelog: all notable changes to this file will be documented
"""
import time

from datetime import datetime

import pytz

from feedgen.feed import FeedGenerator

from src.common.db_utils import get_doc_source_name_dict
from src.common.doc_utils import get_bak_doc_link
from src.config import Config
from src.databases.mongodb_base import MongodbManager
from src.databases.mongodb_tools import mongodb_find, mongodb_update_data
from src.utils import LOGGER


def to_rss(
    doc_source_list: list = None,
    link_source: str = "self",
    skip_ads: bool = False,
    rss_count: int = 20,
    **kwargs,
):
    """ä¸ºæ–‡ç« ç”ŸæˆRSS

    Args:
        doc_source_list (list, optional): æ–‡ç« æ¥æºåˆ—è¡¨. Defaults to None.
        link_source (str, optional): é“¾æ¥è¿”å›è§„åˆ™ç±»å‹ï¼ŒåŸºäºå¤‡ä»½å™¨ï¼Œç›®å‰æ”¯æŒå­—æ®µå¦‚ä¸‹:
            - self: ä¸æ›¿æ¢ï¼Œç”¨æœ¬èº«çš„ doc_link
            - mongodb: ç”¨ liuli api æœåŠ¡çš„è¿æ¥ {LL_DOMAIN}/backup/{doc_source}/{doc_source_name}/{doc_name}
            - github: ç”¨ github ä»“åº“åœ°å€ {LL_GITHUB_DOMAIN}/{doc_source}/{doc_source_name}/{doc_name}.html
        skip_ads (bool, optional): æ˜¯å¦ç›´æ¥å¿½ç•¥å¹¿å‘Š. Defaults to False.
        rss_count (int, optional): ç”Ÿæˆrssçš„æ–‡ç« æ•°é‡. Defaults to 20.
    """
    doc_source_list = doc_source_list or []
    # å…¼å®¹é…ç½®ä¸­çš„å…¨å±€æŸ¥è¯¢æ¡ä»¶
    basic_filter = kwargs.get("basic_filter", {})
    if basic_filter:
        # å½“å‰æƒ…å†µä¸‹å¿…å­˜åœ¨
        doc_source_list.append(basic_filter["doc_source"])
        doc_source_list = list(set(doc_source_list))
    # è·å– doc_source ä¸‹çš„ doc_source_name ç»„æˆçš„å­—å…¸
    doc_source_name_dict: dict = get_doc_source_name_dict(doc_source_list)
    # æ•°æ®åº“åˆå§‹åŒ–
    mongo_base = MongodbManager.get_mongo_base(mongodb_config=Config.LL_MONGODB_CONFIG)
    coll_articles_conn = mongo_base.get_collection(
        coll_name="liuli_articles", db_name="liuli"
    )
    coll_rss_conn = mongo_base.get_collection(coll_name="liuli_rss", db_name="liuli")
    for doc_source, doc_source_name_list in doc_source_name_dict.items():
        for doc_source_name in doc_source_name_list:
            filter_dict = {"doc_source_name": doc_source_name, "doc_source": doc_source}
            if skip_ads:
                filter_dict.update(
                    {
                        # è‡³å°‘æ‰“ä¸Šä¸€ä¸ªæ¨¡å‹æ ‡ç­¾
                        "cos_model": {"$exists": True},
                        # åˆ¤å®šç»“æœä¸ºéå¹¿å‘Š
                        "cos_model.result": 1,
                    }
                )
            return_dict = {
                "_id": 0,
                "doc_source_name": 1,
                "doc_source": 1,
                "doc_name": 1,
                "doc_des": 1,
                "doc_link": 1,
                # "doc_core_html": 1,
                "doc_author": 1,
                "doc_date": 1,
                "doc_ts": 1,
                "cos_model": 1,
            }
            # æå–æ–‡ç« 
            f_db_res = mongodb_find(
                coll_conn=coll_articles_conn,
                filter_dict=filter_dict,
                return_dict=return_dict,
                # å€’åºï¼Œä»æœ€æ–°å‘çš„å¼€å§‹
                sorted_list=[("doc_ts", -1)],
                # æœ€è¿‘ rss_count ç¯‡æ–‡ç« 
                limit=rss_count,
            )
            f_db_satus, f_db_info = f_db_res["status"], f_db_res["info"]
            if f_db_satus:
                if f_db_info:
                    # æŸ¥è¯¢æˆåŠŸä¸”æœ‰æ•°æ®
                    fg = FeedGenerator()
                    fg.id(doc_source_name)
                    fg.title(doc_source_name)
                    fg.author({"name": "Liuli"})
                    fg.generator(
                        generator="Liuli",
                        version=Config.VERSION,
                        uri="https://github.com/liuli-io/liuli",
                    )
                    # å†å€’åº
                    for each_data in f_db_info[::-1]:
                        cos_model_resp = each_data.get("cos_model", {})
                        doc_cus_des = ""
                        if cos_model_resp:
                            # ç»è¿‡æ¨¡å‹åˆ¤æ–­
                            if cos_model_resp["result"] == 1:
                                # å¹¿å‘Šæ ‡è®°
                                doc_cus_des = f"ğŸ‘¿å¹¿å‘Š[æ¦‚ç‡ï¼š{cos_model_resp['probability']}]"
                            else:
                                # doc_cus_des = "ğŸ¤“éå¹¿å‘Š"
                                doc_cus_des = ""
                        doc_name = each_data["doc_name"]
                        if not doc_name:
                            continue
                        doc_des = each_data["doc_des"]
                        doc_link = get_bak_doc_link(
                            link_source=link_source, doc_data=each_data
                        )
                        doc_author = (
                            each_data["doc_author"]
                            or each_data["doc_source_name"]
                            or "liuli_default"
                        )
                        doc_ts = each_data["doc_ts"]
                        doc_date = pytz.timezone("Asia/Shanghai").localize(
                            datetime.fromtimestamp(int(doc_ts))
                        )
                        # æ„é€  RSS
                        fe = fg.add_entry()
                        article_id = f"{doc_source} - {doc_source_name} - {doc_name}"
                        fe.id(article_id)
                        fe.title(f"{doc_name} {doc_cus_des}")
                        fe.link(href=doc_link)
                        fe.description(doc_des)
                        fe.author(name=f"{doc_source} - {doc_author}")
                        # å†…å®¹å…ˆä¸ºç©º
                        fe.content("")
                        fe.updated(doc_date)
                        fe.pubDate(doc_date)
                    try:
                        rss_data = str(fg.atom_str(pretty=True), "utf-8")
                        # æ›´æ–° RSS å†…å®¹
                        rss_db_data = {
                            "doc_source": doc_source,
                            "doc_source_name": doc_source_name,
                            "rss_data": rss_data,
                            "updated_at": int(time.time()),
                        }
                        rss_db_res = mongodb_update_data(
                            coll_conn=coll_rss_conn,
                            filter_dict=filter_dict,
                            update_data={"$set": rss_db_data},
                        )
                        if rss_db_res["status"]:
                            msg = f"ğŸ˜€ ä¸º{doc_source}: {doc_source_name} çš„ {len(f_db_info)} ç¯‡æ–‡ç« ç”ŸæˆRSSæˆåŠŸ!"
                        else:
                            msg = f"ğŸ˜¿ ä¸º{doc_source}: {doc_source_name} çš„ {len(f_db_info)} ç¯‡æ–‡ç« ç”ŸæˆRSSå¤±è´¥!"
                    except Exception as e:
                        msg = f"ğŸ˜¿ ä¸º{doc_source}: {doc_source_name} çš„ {len(f_db_info)} ç¯‡æ–‡ç« ç”ŸæˆRSSå¤±è´¥, éæ³•æ•°æ®! {e}"

                else:
                    msg = f"æŸ¥è¯¢æˆåŠŸ {doc_source}: {doc_source_name} æš‚æ— å†å²æ–‡ç« !"
                LOGGER.info(msg)
            else:
                # æŸ¥è¯¢å¤±è´¥
                LOGGER.error(f"{doc_source}: {doc_source_name} å†å²æ–‡ç« æŸ¥è¯¢å¤±è´¥!")


if __name__ == "__main__":
    to_rss(
        link_source="github",
        skip_ads=False,
        # **{"basic_filter": {"doc_source": "liuli_wechat"}},
    )
